{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SharWarr/ML_Projects/blob/main/Ecommerce_Churn/NB-4_Random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXyoXAzRq_RY"
      },
      "outputs": [],
      "source": [
        "# Setting the environment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7rB8hhTq_Ra"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "os.environ[\"PYSPARK_PYTHON\"]=\"/usr/bin/python3\"\n",
        "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/usr/bin/python3\"\n",
        "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"]=\"notebook --no-browser\"\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_161/jre\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/spark-2.4.4-bin-hadoop2.7\"\n",
        "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
        "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.7-src.zip\")\n",
        "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HxNNW1Gq_Ra"
      },
      "outputs": [],
      "source": [
        "# Spark environment\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUIigF85q_Ra",
        "outputId": "c7e7b602-0e9a-4019-a581-84602ed0c79a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23/02/20 14:40:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "23/02/20 14:40:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ip-172-31-92-239.ec2.internal:4041\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.4</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>demo</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f6b2f88ced0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MAX_MEMORY = \"14G\"\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"demo\") \\\n",
        "    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBqIjArsq_Rb"
      },
      "source": [
        "# Ecommerce Churn Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td1PlVahq_Rc"
      },
      "source": [
        "The aim of the assignment is to build a model that predicts whether a person purchases an item after it has been added to the cart or not. Being a classification problem, you are expected to use your understanding of all the three models covered till now. You must select the most robust model and provide a solution that predicts the churn in the most suitable manner. \n",
        "\n",
        "For this assignment, you are provided the data associated with an e-commerce company for the month of October 2019. Your task is to first analyse the data, and then perform multiple steps towards the model building process.\n",
        "\n",
        "The broad tasks are:\n",
        "- Data Exploration\n",
        "- Feature Engineering\n",
        "- Model Selection\n",
        "- Model Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HR1HL9lq_Rc"
      },
      "source": [
        "### Data description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2td30diPq_Rd"
      },
      "source": [
        "The dataset stores the information of a customer session on the e-commerce platform. It records the activity and the associated parameters with it.\n",
        "\n",
        "- **event_time**: Date and time when user accesses the platform\n",
        "- **event_type**: Action performed by the customer\n",
        "            - View\n",
        "            - Cart\n",
        "            - Purchase\n",
        "            - Remove from cart\n",
        "- **product_id**: Unique number to identify the product in the event\n",
        "- **category_id**: Unique number to identify the category of the product\n",
        "- **category_code**: Stores primary and secondary categories of the product\n",
        "- **brand**: Brand associated with the product\n",
        "- **price**: Price of the product\n",
        "- **user_id**: Unique ID for a customer\n",
        "- **user_session**: Session ID for a user\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38vQN7m5q_Rd"
      },
      "source": [
        "### Initialising the SparkSession"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh7JWfRzq_Rd"
      },
      "source": [
        "The dataset provided is 5 GBs in size. Therefore, it is expected that you increase the driver memory to a greater number. You can refer to notebook 1 for the steps involved here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqUsJo3pq_Re",
        "outputId": "a0430923-463e-4f4a-8909-58a290c4947c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Loading the clean data\n",
        "\n",
        "df=spark.read.parquet(\"Cleaned_df_final_parquet.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU69n46cq_Re"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Bucketizer\n",
        "bucketizer = Bucketizer(splits=[ 0, 6, 12, 18, 24 ],inputCol=\"Hour\", outputCol=\"Hour_binned\")\n",
        "df_buck = bucketizer.setHandleInvalid(\"keep\").transform(df)\n",
        "\n",
        "from pyspark.sql.types import IntegerType,FloatType\n",
        "df_buck = df_buck.withColumn(\"Hour_binned\", df_buck[\"Hour_binned\"].cast(IntegerType()))\n",
        "\n",
        "# Check if only the required columns are present to build the model\n",
        "# If not, drop the redundant columns\n",
        "df_buck = df_buck.fillna(value ='no category',subset =['category_2'])\n",
        "df_buck = df_buck.withColumn(\"price\", df_buck[\"price\"].cast(FloatType()))\n",
        "df_buck = df_buck.drop(\"category_code\",\"user_id\",\"product_id\",\"brand\",\"Hour\",\"category_id\",\"user_session\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--3J9ma5q_Re"
      },
      "source": [
        "## Task 3: Model Selection\n",
        "3 models for classification:\t\n",
        "- Logistic Regression\n",
        "- Decision Tree\n",
        "- Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPVrg-UFq_Re"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngQNToUPq_Rf",
        "outputId": "9519e88c-977d-4718-9a2d-55af471d814c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "# Feature transformation for categorical features\n",
        "indexer = StringIndexer(inputCol=\"event_type\", outputCol=\"event_type_cat\")\n",
        "indexed = indexer.fit(df_buck).transform(df_buck)\n",
        "# Feature transformation for categorical features\n",
        "indexer = StringIndexer(inputCol=\"category_1\", outputCol=\"category_1_cat\")\n",
        "indexed = indexer.fit(indexed).transform(indexed)\n",
        "# Feature transformation for categorical features\n",
        "indexer = StringIndexer(inputCol=\"category_2\", outputCol=\"category_2_cat\")\n",
        "indexed = indexer.fit(indexed).transform(indexed)\n",
        "# Feature transformation for categorical features\n",
        "indexer = StringIndexer(inputCol=\"brand_new\", outputCol=\"brand_new_cat\")\n",
        "indexed = indexer.fit(indexed).transform(indexed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFgzpkVCq_Rf",
        "outputId": "624f9660-a29f-4da8-d8e7-624669fa3f69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['event_type',\n",
              " 'price',\n",
              " 'category_1',\n",
              " 'category_2',\n",
              " 'brand_new',\n",
              " 'target',\n",
              " 'Hour_binned',\n",
              " 'event_type_cat',\n",
              " 'category_1_cat',\n",
              " 'category_2_cat',\n",
              " 'brand_new_cat']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indexed.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOxkAXBAq_Rf"
      },
      "outputs": [],
      "source": [
        "#Creating Vector Assembler to combine all the raw features\n",
        "# Vector assembler to combine all the features\n",
        "assembler = VectorAssembler(inputCols=[\n",
        " 'price',\n",
        " 'Hour_binned',\n",
        " 'event_type_cat',\n",
        " 'category_1_cat',\n",
        " 'brand_new_cat'], outputCol=\"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lScCh2vq_Rf"
      },
      "outputs": [],
      "source": [
        "output = assembler.transform(indexed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E_mG4sUq_Rf",
        "outputId": "4eb1d218-d2fc-4a83-83bc-269845371d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+------+-----------+--------------------+---------+------+-----------+--------------+--------------+--------------+-------------+--------------------+\n",
            "|event_type| price| category_1|          category_2|brand_new|target|Hour_binned|event_type_cat|category_1_cat|category_2_cat|brand_new_cat|            features|\n",
            "+----------+------+-----------+--------------------+---------+------+-----------+--------------+--------------+--------------+-------------+--------------------+\n",
            "|      view|341.74|electronics|         no category|   xiaomi|     0|          1|           0.0|           0.0|           0.0|          4.0|[341.739990234375...|\n",
            "|      view| 36.04|no category|         no category| no brand|     0|          1|           0.0|           1.0|           0.0|          1.0|[36.0400009155273...|\n",
            "|      view| 34.11|no category|         no category|   Others|     0|          1|           0.0|           1.0|           0.0|          0.0|[34.1100006103515...|\n",
            "|      view| 63.06|no category|         no category|   Others|     0|          2|           0.0|           1.0|           0.0|          0.0|[63.0600013732910...|\n",
            "|      view|341.91|no category|         no category| no brand|     0|          2|           0.0|           1.0|           0.0|          1.0|[341.910003662109...|\n",
            "|      view|362.34|no category|         no category| no brand|     0|          2|           0.0|           1.0|           0.0|          1.0|[362.339996337890...|\n",
            "|      view|341.91|no category|         no category| no brand|     0|          2|           0.0|           1.0|           0.0|          1.0|[341.910003662109...|\n",
            "|      view|392.38|no category|         no category| no brand|     0|          2|           0.0|           1.0|           0.0|          1.0|[392.380004882812...|\n",
            "|      view|339.28|no category|         no category| no brand|     0|          2|           0.0|           1.0|           0.0|          1.0|[339.279998779296...|\n",
            "|      view|448.84|no category|         no category| no brand|     0|          2|           0.0|           1.0|           0.0|          1.0|[448.839996337890...|\n",
            "|      view|283.12| appliances|kitchen.refrigera...| no brand|     0|          2|           0.0|           2.0|           3.0|          1.0|[283.119995117187...|\n",
            "|      view|225.23| appliances|kitchen.refrigera...| no brand|     0|          2|           0.0|           2.0|           3.0|          1.0|[225.229995727539...|\n",
            "|      view|283.12| appliances|kitchen.refrigera...|   Others|     0|          2|           0.0|           2.0|           3.0|          0.0|[283.119995117187...|\n",
            "|      view|225.23| appliances|kitchen.refrigera...| no brand|     0|          2|           0.0|           2.0|           3.0|          1.0|[225.229995727539...|\n",
            "|      view|228.47| appliances|kitchen.refrigera...| no brand|     0|          2|           0.0|           2.0|           3.0|          1.0|[228.470001220703...|\n",
            "|      view|283.12| appliances|kitchen.refrigera...| no brand|     0|          2|           0.0|           2.0|           3.0|          1.0|[283.119995117187...|\n",
            "|      view|952.03|electronics|         no category|   huawei|     0|          2|           0.0|           0.0|           0.0|          5.0|[952.030029296875...|\n",
            "|      view|196.91|electronics|         no category|   xiaomi|     0|          1|           0.0|           0.0|           0.0|          4.0|[196.910003662109...|\n",
            "|      view|153.98|electronics|         no category|   huawei|     0|          0|           0.0|           0.0|           0.0|          5.0|(5,[0,4],[153.979...|\n",
            "|      view|166.54|electronics|         no category|   huawei|     0|          0|           0.0|           0.0|           0.0|          5.0|(5,[0,4],[166.539...|\n",
            "+----------+------+-----------+--------------------+---------+------+-----------+--------------+--------------+--------------+-------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "output.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "pPXDH7j5q_Rf",
        "outputId": "23945fb6-2c59-4cc6-9886-96d78a4bf8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------+\n",
            "|            features|target|\n",
            "+--------------------+------+\n",
            "|[341.739990234375...|     0|\n",
            "|[36.0400009155273...|     0|\n",
            "|[34.1100006103515...|     0|\n",
            "|[63.0600013732910...|     0|\n",
            "|[341.910003662109...|     0|\n",
            "|[362.339996337890...|     0|\n",
            "|[341.910003662109...|     0|\n",
            "|[392.380004882812...|     0|\n",
            "|[339.279998779296...|     0|\n",
            "|[448.839996337890...|     0|\n",
            "|[283.119995117187...|     0|\n",
            "|[225.229995727539...|     0|\n",
            "|[283.119995117187...|     0|\n",
            "|[225.229995727539...|     0|\n",
            "|[228.470001220703...|     0|\n",
            "|[283.119995117187...|     0|\n",
            "|[952.030029296875...|     0|\n",
            "|[196.910003662109...|     0|\n",
            "|(5,[0,4],[153.979...|     0|\n",
            "|(5,[0,4],[166.539...|     0|\n",
            "+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check if only the required columns are present to build the model\n",
        "# If not, drop the redundant columns\n",
        "output.select(\"features\",\"target\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3MVRhtvq_Rf"
      },
      "source": [
        "### Model 3: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCIUtvdcq_Rg"
      },
      "outputs": [],
      "source": [
        "model_df = output.select(\"features\",\"target\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ra1inJxq_Rg"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into train and test (Remember you are expected to compare the model later)\n",
        "training_df, test_df = model_df.randomSplit([0.7,0.3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUgcGFZnq_Rg",
        "outputId": "58970bad-24cd-4376-990b-4b5d266b7de8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "29690946"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Number of rows in train and test data\n",
        "training_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "LVkciPO8q_Rg",
        "outputId": "50975df7-67ab-4287-8397-c7ea297d2abc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "12727598"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V68r757Nq_Rg"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV8RBYqeq_Rh"
      },
      "outputs": [],
      "source": [
        "# Building the RF model\n",
        "\n",
        "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'target', \\\n",
        "                            maxDepth=5, impurity='gini', numTrees=25, seed=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pr1IO_lUq_Rh",
        "outputId": "177dfeeb-ca16-4461-9eff-426fd6332720"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 21:>                                                         (0 + 4) / 7]23/02/20 15:02:35 WARN MemoryStore: Not enough space to cache rdd_77_3 in memory! (computed 770.4 MB so far)\n",
            "23/02/20 15:02:35 WARN MemoryStore: Not enough space to cache rdd_77_2 in memory! (computed 770.4 MB so far)\n",
            "23/02/20 15:02:35 WARN BlockManager: Persisting block rdd_77_3 to disk instead.\n",
            "23/02/20 15:02:35 WARN BlockManager: Persisting block rdd_77_2 to disk instead.\n",
            "23/02/20 15:02:35 WARN MemoryStore: Not enough space to cache rdd_77_0 in memory! (computed 770.4 MB so far)\n",
            "23/02/20 15:02:35 WARN BlockManager: Persisting block rdd_77_0 to disk instead.\n",
            "23/02/20 15:02:44 WARN MemoryStore: Not enough space to cache rdd_77_1 in memory! (computed 1159.0 MB so far)\n",
            "23/02/20 15:02:44 WARN BlockManager: Persisting block rdd_77_1 to disk instead.\n",
            "[Stage 21:=================================>                        (4 + 3) / 7]23/02/20 15:04:37 WARN MemoryStore: Not enough space to cache rdd_77_4 in memory! (computed 216.8 MB so far)\n",
            "23/02/20 15:04:37 WARN BlockManager: Persisting block rdd_77_4 to disk instead.\n",
            "23/02/20 15:04:44 WARN MemoryStore: Not enough space to cache rdd_77_5 in memory! (computed 770.4 MB so far)\n",
            "23/02/20 15:04:44 WARN BlockManager: Persisting block rdd_77_5 to disk instead.\n",
            "[Stage 21:=================================>                        (4 + 3) / 7]23/02/20 15:04:47 WARN MemoryStore: Not enough space to cache rdd_77_6 in memory! (computed 27.0 MB so far)\n",
            "23/02/20 15:04:47 WARN BlockManager: Persisting block rdd_77_6 to disk instead.\n",
            "23/02/20 15:05:13 WARN MemoryStore: Not enough space to cache rdd_77_5 in memory! (computed 1159.0 MB so far)\n",
            "23/02/20 15:05:16 WARN MemoryStore: Not enough space to cache rdd_77_4 in memory! (computed 1159.0 MB so far)\n",
            "[Stage 23:========================>                                 (3 + 4) / 7]23/02/20 15:06:19 WARN MemoryStore: Not enough space to cache rdd_77_5 in memory! (computed 513.6 MB so far)\n",
            "23/02/20 15:06:19 WARN MemoryStore: Not enough space to cache rdd_77_4 in memory! (computed 513.6 MB so far)\n",
            "[Stage 25:=================================>                        (4 + 3) / 7]23/02/20 15:07:29 WARN MemoryStore: Not enough space to cache rdd_77_4 in memory! (computed 513.6 MB so far)\n",
            "23/02/20 15:07:30 WARN MemoryStore: Not enough space to cache rdd_77_5 in memory! (computed 513.6 MB so far)\n",
            "[Stage 27:=================================>                        (4 + 3) / 7]23/02/20 15:08:46 WARN MemoryStore: Not enough space to cache rdd_77_5 in memory! (computed 513.6 MB so far)\n",
            "23/02/20 15:08:47 WARN MemoryStore: Not enough space to cache rdd_77_4 in memory! (computed 513.6 MB so far)\n",
            "[Stage 29:=================================>                        (4 + 3) / 7]23/02/20 15:10:28 WARN MemoryStore: Not enough space to cache rdd_77_5 in memory! (computed 513.6 MB so far)\n",
            "23/02/20 15:10:29 WARN MemoryStore: Not enough space to cache rdd_77_4 in memory! (computed 513.6 MB so far)\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Fitting the model over the training set\n",
        "rfmodel = rf.fit(training_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7BZALs_q_Rh",
        "outputId": "ec544f76-b0ff-4494-9650-80c9526c1e78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForestClassificationModel (uid=RandomForestClassifier_0e0ed3d148ba) with 25 trees\n",
            "  Tree 0 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 1 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 2 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 3 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 4 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 5 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 6 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 7 (weight 1.0):\n",
            "    If (feature 1 <= 1.5)\n",
            "     If (feature 3 in {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "     Else (feature 3 not in {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "    Else (feature 1 > 1.5)\n",
            "     If (feature 0 <= 210.47999572753906)\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "     Else (feature 0 > 210.47999572753906)\n",
            "      If (feature 4 in {0.0,1.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0})\n",
            "       If (feature 0 <= 437.6300048828125)\n",
            "        If (feature 2 in {1.0,2.0})\n",
            "         Predict: 1.0\n",
            "        Else (feature 2 not in {1.0,2.0})\n",
            "         Predict: 0.0\n",
            "       Else (feature 0 > 437.6300048828125)\n",
            "        If (feature 2 in {1.0,2.0})\n",
            "         Predict: 1.0\n",
            "        Else (feature 2 not in {1.0,2.0})\n",
            "         Predict: 0.0\n",
            "      Else (feature 4 not in {0.0,1.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0})\n",
            "       If (feature 2 in {1.0,2.0})\n",
            "        Predict: 1.0\n",
            "       Else (feature 2 not in {1.0,2.0})\n",
            "        Predict: 0.0\n",
            "  Tree 8 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 9 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 10 (weight 1.0):\n",
            "    If (feature 1 <= 1.5)\n",
            "     If (feature 0 <= 308.0849914550781)\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "     Else (feature 0 > 308.0849914550781)\n",
            "      If (feature 3 in {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "       If (feature 0 <= 741.9849853515625)\n",
            "        Predict: 0.0\n",
            "       Else (feature 0 > 741.9849853515625)\n",
            "        If (feature 2 in {1.0,2.0})\n",
            "         Predict: 1.0\n",
            "        Else (feature 2 not in {1.0,2.0})\n",
            "         Predict: 0.0\n",
            "      Else (feature 3 not in {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "       If (feature 2 in {1.0,2.0})\n",
            "        Predict: 1.0\n",
            "       Else (feature 2 not in {1.0,2.0})\n",
            "        Predict: 0.0\n",
            "    Else (feature 1 > 1.5)\n",
            "     If (feature 2 in {1.0,2.0})\n",
            "      Predict: 1.0\n",
            "     Else (feature 2 not in {1.0,2.0})\n",
            "      Predict: 0.0\n",
            "  Tree 11 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 12 (weight 1.0):\n",
            "    If (feature 1 <= 1.5)\n",
            "     If (feature 2 in {1.0,2.0})\n",
            "      Predict: 1.0\n",
            "     Else (feature 2 not in {1.0,2.0})\n",
            "      Predict: 0.0\n",
            "    Else (feature 1 > 1.5)\n",
            "     If (feature 2 in {1.0,2.0})\n",
            "      Predict: 1.0\n",
            "     Else (feature 2 not in {1.0,2.0})\n",
            "      Predict: 0.0\n",
            "  Tree 13 (weight 1.0):\n",
            "    If (feature 1 <= 1.5)\n",
            "     If (feature 2 in {1.0,2.0})\n",
            "      Predict: 1.0\n",
            "     Else (feature 2 not in {1.0,2.0})\n",
            "      Predict: 0.0\n",
            "    Else (feature 1 > 1.5)\n",
            "     If (feature 3 in {3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "      If (feature 0 <= 346.5800018310547)\n",
            "       If (feature 0 <= 125.61999893188477)\n",
            "        If (feature 2 in {1.0,2.0})\n",
            "         Predict: 1.0\n",
            "        Else (feature 2 not in {1.0,2.0})\n",
            "         Predict: 0.0\n",
            "       Else (feature 0 > 125.61999893188477)\n",
            "        Predict: 0.0\n",
            "      Else (feature 0 > 346.5800018310547)\n",
            "       If (feature 3 in {4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "        If (feature 2 in {1.0,2.0})\n",
            "         Predict: 1.0\n",
            "        Else (feature 2 not in {1.0,2.0})\n",
            "         Predict: 0.0\n",
            "       Else (feature 3 not in {4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "        Predict: 0.0\n",
            "     Else (feature 3 not in {3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "  Tree 14 (weight 1.0):\n",
            "    If (feature 1 <= 1.5)\n",
            "     If (feature 2 in {1.0,2.0})\n",
            "      Predict: 1.0\n",
            "     Else (feature 2 not in {1.0,2.0})\n",
            "      Predict: 0.0\n",
            "    Else (feature 1 > 1.5)\n",
            "     If (feature 0 <= 210.47999572753906)\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "     Else (feature 0 > 210.47999572753906)\n",
            "      If (feature 4 in {0.0,1.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0})\n",
            "       If (feature 2 in {1.0,2.0})\n",
            "        Predict: 1.0\n",
            "       Else (feature 2 not in {1.0,2.0})\n",
            "        Predict: 0.0\n",
            "      Else (feature 4 not in {0.0,1.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0})\n",
            "       If (feature 2 in {1.0,2.0})\n",
            "        Predict: 1.0\n",
            "       Else (feature 2 not in {1.0,2.0})\n",
            "        Predict: 0.0\n",
            "  Tree 15 (weight 1.0):\n",
            "    If (feature 0 <= 252.2449951171875)\n",
            "     If (feature 1 <= 1.5)\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "     Else (feature 1 > 1.5)\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "    Else (feature 0 > 252.2449951171875)\n",
            "     If (feature 4 in {0.0,1.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0})\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "     Else (feature 4 not in {0.0,1.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0})\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "  Tree 16 (weight 1.0):\n",
            "    If (feature 1 <= 1.5)\n",
            "     If (feature 0 <= 308.0849914550781)\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "     Else (feature 0 > 308.0849914550781)\n",
            "      If (feature 4 in {0.0,1.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0})\n",
            "       If (feature 0 <= 952.1000061035156)\n",
            "        If (feature 2 in {1.0,2.0})\n",
            "         Predict: 1.0\n",
            "        Else (feature 2 not in {1.0,2.0})\n",
            "         Predict: 0.0\n",
            "       Else (feature 0 > 952.1000061035156)\n",
            "        If (feature 2 in {1.0,2.0})\n",
            "         Predict: 1.0\n",
            "        Else (feature 2 not in {1.0,2.0})\n",
            "         Predict: 0.0\n",
            "      Else (feature 4 not in {0.0,1.0,2.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0})\n",
            "       If (feature 2 in {1.0,2.0})\n",
            "        Predict: 1.0\n",
            "       Else (feature 2 not in {1.0,2.0})\n",
            "        Predict: 0.0\n",
            "    Else (feature 1 > 1.5)\n",
            "     If (feature 3 in {3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "     Else (feature 3 not in {3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "  Tree 17 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 18 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 19 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 20 (weight 1.0):\n",
            "    If (feature 1 <= 1.5)\n",
            "     If (feature 2 in {1.0,2.0})\n",
            "      Predict: 1.0\n",
            "     Else (feature 2 not in {1.0,2.0})\n",
            "      Predict: 0.0\n",
            "    Else (feature 1 > 1.5)\n",
            "     If (feature 0 <= 210.47999572753906)\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "     Else (feature 0 > 210.47999572753906)\n",
            "      If (feature 2 in {1.0,2.0})\n",
            "       Predict: 1.0\n",
            "      Else (feature 2 not in {1.0,2.0})\n",
            "       Predict: 0.0\n",
            "  Tree 21 (weight 1.0):\n",
            "    If (feature 1 <= 1.5)\n",
            "     If (feature 2 in {1.0,2.0})\n",
            "      If (feature 3 in {4.0,5.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "       If (feature 2 in {1.0})\n",
            "        If (feature 3 in {4.0})\n",
            "         Predict: 0.0\n",
            "        Else (feature 3 not in {4.0})\n",
            "         Predict: 1.0\n",
            "       Else (feature 2 not in {1.0})\n",
            "        Predict: 1.0\n",
            "      Else (feature 3 not in {4.0,5.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "       Predict: 1.0\n",
            "     Else (feature 2 not in {1.0,2.0})\n",
            "      Predict: 0.0\n",
            "    Else (feature 1 > 1.5)\n",
            "     If (feature 2 in {1.0,2.0})\n",
            "      Predict: 1.0\n",
            "     Else (feature 2 not in {1.0,2.0})\n",
            "      Predict: 0.0\n",
            "  Tree 22 (weight 1.0):\n",
            "    If (feature 1 <= 1.5)\n",
            "     If (feature 3 in {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "      If (feature 3 in {3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "       If (feature 2 in {1.0,2.0})\n",
            "        Predict: 1.0\n",
            "       Else (feature 2 not in {1.0,2.0})\n",
            "        Predict: 0.0\n",
            "      Else (feature 3 not in {3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "       If (feature 2 in {1.0,2.0})\n",
            "        Predict: 1.0\n",
            "       Else (feature 2 not in {1.0,2.0})\n",
            "        Predict: 0.0\n",
            "     Else (feature 3 not in {1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0})\n",
            "      If (feature 4 in {0.0,1.0,4.0,5.0,7.0,8.0,9.0,10.0,11.0,13.0,14.0,15.0,16.0,18.0})\n",
            "       If (feature 0 <= 437.6300048828125)\n",
            "        Predict: 0.0\n",
            "       Else (feature 0 > 437.6300048828125)\n",
            "        If (feature 2 in {1.0,2.0})\n",
            "         Predict: 1.0\n",
            "        Else (feature 2 not in {1.0,2.0})\n",
            "         Predict: 0.0\n",
            "      Else (feature 4 not in {0.0,1.0,4.0,5.0,7.0,8.0,9.0,10.0,11.0,13.0,14.0,15.0,16.0,18.0})\n",
            "       If (feature 2 in {1.0,2.0})\n",
            "        Predict: 1.0\n",
            "       Else (feature 2 not in {1.0,2.0})\n",
            "        Predict: 0.0\n",
            "    Else (feature 1 > 1.5)\n",
            "     If (feature 2 in {1.0,2.0})\n",
            "      Predict: 1.0\n",
            "     Else (feature 2 not in {1.0,2.0})\n",
            "      Predict: 0.0\n",
            "  Tree 23 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "  Tree 24 (weight 1.0):\n",
            "    If (feature 2 in {1.0,2.0})\n",
            "     Predict: 1.0\n",
            "    Else (feature 2 not in {1.0,2.0})\n",
            "     Predict: 0.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Printing the forest obtained from the model\n",
        "print(rfmodel.toDebugString)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ideE7l5q_Rh"
      },
      "outputs": [],
      "source": [
        "# Applying the model on test set\n",
        "predictions = rfmodel.transform(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfxhTshCq_Rh",
        "outputId": "8519dd00-d572-4ee1-8a36-4e59f1d49dee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[features: vector, target: int, rawPrediction: vector, probability: vector, prediction: double]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hOSQHboq_Rh",
        "outputId": "1e22655c-1762-4fe8-bee7-55bfd99368c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 32:>                                                         (0 + 1) / 1]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------+--------------------+--------------------+----------+\n",
            "|            features|target|       rawPrediction|         probability|prediction|\n",
            "+--------------------+------+--------------------+--------------------+----------+\n",
            "|(5,[0],[0.8799999...|     0|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|(5,[0],[0.8799999...|     0|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|(5,[0],[0.8799999...|     1|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|(5,[0],[0.8799999...|     1|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|(5,[0],[0.8799999...|     1|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|(5,[0],[0.8799999...|     1|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|(5,[0],[0.8799999...|     1|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|       (5,[0],[1.0])|     0|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|       (5,[0],[1.0])|     0|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|       (5,[0],[1.0])|     0|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|       (5,[0],[1.0])|     0|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|       (5,[0],[1.0])|     0|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|       (5,[0],[1.0])|     1|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|       (5,[0],[1.0])|     1|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|       (5,[0],[1.0])|     1|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|(5,[0],[1.1299999...|     0|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|(5,[0],[1.1299999...|     0|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|      (5,[0],[1.25])|     0|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|      (5,[0],[1.25])|     0|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "|      (5,[0],[1.25])|     1|[16.9378453510291...|[0.67751381404116...|       0.0|\n",
            "+--------------------+------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "predictions.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvyJbDS1q_Rh",
        "outputId": "23789d6e-9b81-4927-c35e-d84bc75816e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 33:>                                                         (0 + 1) / 1]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------------+----------+--------------------+\n",
            "|target|       rawPrediction|prediction|         probability|\n",
            "+------+--------------------+----------+--------------------+\n",
            "|     0|[16.9378453510291...|       0.0|[0.67751381404116...|\n",
            "|     0|[16.9378453510291...|       0.0|[0.67751381404116...|\n",
            "|     1|[16.9378453510291...|       0.0|[0.67751381404116...|\n",
            "|     1|[16.9378453510291...|       0.0|[0.67751381404116...|\n",
            "|     1|[16.9378453510291...|       0.0|[0.67751381404116...|\n",
            "|     1|[16.9378453510291...|       0.0|[0.67751381404116...|\n",
            "|     1|[16.9378453510291...|       0.0|[0.67751381404116...|\n",
            "|     0|[16.9378453510291...|       0.0|[0.67751381404116...|\n",
            "|     0|[16.9378453510291...|       0.0|[0.67751381404116...|\n",
            "|     0|[16.9378453510291...|       0.0|[0.67751381404116...|\n",
            "+------+--------------------+----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Printing the required columns\n",
        "predictions.select('target', 'rawPrediction', 'prediction', 'probability').show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOdINA_lq_Ri"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKecDOVJq_Ri"
      },
      "source": [
        "#### Feature Transformation (Code will be same; check for the columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHPSz5aaq_Ri"
      },
      "outputs": [],
      "source": [
        "# Check if only the required columns are present to build the model\n",
        "# If not, drop the redundant columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgofDOE4q_Ri"
      },
      "outputs": [],
      "source": [
        "# Categorising the attributes into its type - Continuous and Categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGXCPhNZq_Ri"
      },
      "outputs": [],
      "source": [
        "# Feature transformation for categorical features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYKqF8Rtq_Ri"
      },
      "outputs": [],
      "source": [
        "# Vector assembler to combine all the features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CNe5RKIq_Ri"
      },
      "outputs": [],
      "source": [
        "# Pipeline for the tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWJtU6F8q_Ri"
      },
      "outputs": [],
      "source": [
        "# Transforming the dataframe df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqLCrlBiq_Ri"
      },
      "outputs": [],
      "source": [
        "# Schema of the transformed df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU19vXr-q_Ri"
      },
      "outputs": [],
      "source": [
        "# Checking the elements of the transformed df - Top 20 rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_fYRdzkq_Ri"
      },
      "outputs": [],
      "source": [
        "# Storing the transformed df in S3 bucket to prevent repetition of steps again\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xaodmli2q_Rj"
      },
      "source": [
        "#### Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1fP4piJq_Rj"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into train and test (Remember you are expected to compare the model later)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1vmWWtqq_Rj"
      },
      "outputs": [],
      "source": [
        "# Number of rows in train and test data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqBpsJ0Iq_Rj"
      },
      "source": [
        "#### Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MyQ7lsIq_Rj"
      },
      "outputs": [],
      "source": [
        "# Building the model with hyperparameter tuning\n",
        "# Create ParamGrid for Cross Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAyIa6Uvq_Rj"
      },
      "outputs": [],
      "source": [
        "# Run cross-validation steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2SKti9zq_Rj"
      },
      "outputs": [],
      "source": [
        "# Fitting the models on transformed df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOVslRXaq_Rj"
      },
      "outputs": [],
      "source": [
        "# Best model from the results of cross-validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESqdMtBJq_Rj"
      },
      "source": [
        "#### Model Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6qYZDyoq_Rj"
      },
      "source": [
        "Required Steps:\n",
        "- Fit on test data\n",
        "- Performance analysis\n",
        "    - Appropriate Metric with reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnsqLyhcq_Rj"
      },
      "outputs": [],
      "source": [
        "# Model evaluation\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_pwKW8vq_Rk",
        "outputId": "e80f950c-d629-48e5-d818-5446cc8ecc6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "\n",
        "accuracy = evaluator.evaluate(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV-XtGVUq_Rk",
        "outputId": "a7f8d8e3-862b-412a-d63d-12587a9cd450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6940859540032612\n"
          ]
        }
      ],
      "source": [
        "# Model Accuracy\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCGHS-6Aq_Rk",
        "outputId": "914dfc7c-c246-4c85-a2b9-18b83106afb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error = 0.305914\n"
          ]
        }
      ],
      "source": [
        "# Test Error\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRi8FpAnq_Rk",
        "outputId": "06b0e570-69c1-4c6f-9f95-833243802e88"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "# Assuming you have a random forest model called \"rf\" and a test dataset called \"testData\"\n",
        "\n",
        "\n",
        "# Evaluate precision\n",
        "evaluator = MulticlassClassificationEvaluator( labelCol=\"target\", metricName=\"weightedPrecision\")\n",
        "precision = evaluator.evaluate(predictions)\n",
        "\n",
        "# Evaluate recall\n",
        "evaluator = MulticlassClassificationEvaluator( labelCol=\"target\", metricName=\"weightedRecall\")\n",
        "recall = evaluator.evaluate(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYNFwUVtq_Rk",
        "outputId": "1019bfab-d96d-4898-8478-675a942b1d2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6940859540032612"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B3tzGn-q_Rl",
        "outputId": "4ea8822f-0fcc-4178-a521-df6c9133e960"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7442418095503369"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urqb_MR_q_Rl"
      },
      "source": [
        "#### Summary of the best Random Forest model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4GtUWuBq_Rl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shNBwMz7q_Rl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXmPKYmkq_Rl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}